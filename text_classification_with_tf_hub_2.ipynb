{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "code",
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "_8N3Hx2dyUC-"
   },
   "outputs": [],
   "source": [
    "# # Install TF-Hub.\n",
    "# !pip install tensorflow-hub\n",
    "# !pip install seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "v7hy0bhngTUp"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import re\n",
    "import seaborn as sns\n",
    "import pdb\n",
    "import shutil\n",
    "from nltk.tokenize import word_tokenize\n",
    "from typing import Tuple\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "from collections import OrderedDict\n",
    "import json\n",
    "from pprint import pprint\n",
    "# import logging\n",
    "# logging.basicConfig(format='%(levelname)s %(asctime)s : %(message)s', level=logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"-1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!export TFHUB_CACHE_DIR=~/tf_hub_cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "HUB_LINK_DICT = {\n",
    "    'use_dan': \"https://tfhub.dev/google/universal-sentence-encoder/2\",\n",
    "    'use_large': \"https://tfhub.dev/google/universal-sentence-encoder-large/3\",\n",
    "    'nnlm': \"https://tfhub.dev/google/nnlm-en-dim128/1\",\n",
    "    'elmo': \"https://tfhub.dev/google/elmo/2\",\n",
    "    'w2v': \"https://tfhub.dev/google/Wiki-words-500-with-normalization/1\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load all files from a directory in a DataFrame.\n",
    "def load_yelp_train_test(path='pytorch-pretrained-BERT/examples/data'):\n",
    "    train_df = pd.read_csv(os.path.join(path, 'yelp_class_train.csv'), encoding='latin1')\n",
    "    test_df = pd.read_csv(os.path.join(path, 'yelp_class_test.csv'), encoding='latin1')\n",
    "    return train_df, test_df\n",
    "\n",
    "def make_model_dir(path):\n",
    "    if not os.path.exists(path):\n",
    "        os.makedirs(path)\n",
    "    else:\n",
    "        shutil.rmtree(path)\n",
    "        os.makedirs(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TFHubCompositionalitySwitchingPipeline(object):\n",
    "    def __init__(self, model_name: str, finetune_module: bool, last_layer: str = 'linear', num_classes: int = 2,\n",
    "                 lr: float = 0.003, eval_on_train: bool = True, continue_from_ckpt: bool = False, **kwargs):\n",
    "        self.model_name = model_name\n",
    "        self.finetune_module = finetune_module\n",
    "        self.last_layer = last_layer\n",
    "        self.model_id = self.model_name + '_' + str(self.finetune_module) + '_' + self.last_layer\n",
    "        print(\"Model config = {}\".format(self.model_id))\n",
    "        self.num_classes = num_classes\n",
    "        self.lr = lr\n",
    "        self.eval_on_train = eval_on_train\n",
    "        self.continue_from_ckpt = continue_from_ckpt\n",
    "\n",
    "        self.model_url = HUB_LINK_DICT[self.model_name.lower()]\n",
    "        self.train_df, self.test_df = self.load_data()\n",
    "\n",
    "        self.model_config = None\n",
    "        self.estimator = None\n",
    "        self.data_dir = 'pytorch-pretrained-BERT/examples/data/'\n",
    "        self.eval_dict = dict()\n",
    "        self.eval_dict['model_id'] = self.model_id\n",
    "        print(self.train_df.head())\n",
    "        print(self.train_df.shape)\n",
    "        print(self.test_df.shape)\n",
    "\n",
    "    def load_data(self) -> Tuple[pd.DataFrame, pd.DataFrame]:\n",
    "        return load_yelp_train_test()\n",
    "\n",
    "    def build_model(self) -> None:\n",
    "        if not self.continue_from_ckpt:\n",
    "            print(\"Clearing old checkpoints and making new model dir\")\n",
    "            make_model_dir(self.model_id)\n",
    "        embedded_text_feature_column = hub.text_embedding_column(\n",
    "            key=\"text\",\n",
    "            module_spec=self.model_url,\n",
    "            trainable=self.finetune_module)\n",
    "        self.model_config = tf.estimator.RunConfig(\n",
    "            model_dir=self.model_id,\n",
    "            tf_random_seed=123,\n",
    "            save_summary_steps=1000,\n",
    "            keep_checkpoint_max=2,\n",
    "            log_step_count_steps=1000,\n",
    "        )\n",
    "        if self.last_layer == 'linear':\n",
    "            self.estimator = tf.estimator.LinearClassifier(\n",
    "                feature_columns=[embedded_text_feature_column],\n",
    "                n_classes=self.num_classes,\n",
    "                optimizer=tf.train.AdagradOptimizer(learning_rate=self.lr),\n",
    "                config=self.model_config)\n",
    "        elif self.last_layer == 'dnn':\n",
    "            self.estimator = tf.estimator.DNNClassifier(\n",
    "                hidden_units=[500, 100],\n",
    "                feature_columns=[embedded_text_feature_column],\n",
    "                n_classes=self.num_classes,\n",
    "                optimizer=tf.train.AdagradOptimizer(learning_rate=self.lr),\n",
    "                config=self.model_config)\n",
    "        else:\n",
    "            raise ValueError(\"Invalid last layer value, valid options: linear or dnn\")\n",
    "\n",
    "    def train_model(self, num_epochs: int = 3) -> None:\n",
    "        # Training input on the whole training set with no limit on training epochs.\n",
    "        train_input_fn = tf.estimator.inputs.pandas_input_fn(\n",
    "            self.train_df, self.train_df[\"label\"], num_epochs=num_epochs, shuffle=True)\n",
    "\n",
    "        self.estimator.train(input_fn=train_input_fn)\n",
    "\n",
    "    def eval_model(self) -> None:\n",
    "        if self.eval_on_train:\n",
    "            # Prediction on the whole training set.\n",
    "            predict_train_input_fn = tf.estimator.inputs.pandas_input_fn(\n",
    "                self.train_df, self.train_df[\"label\"], shuffle=False)\n",
    "            train_eval_result = self.estimator.evaluate(input_fn=predict_train_input_fn)\n",
    "            print(\"Training set accuracy: {accuracy}\".format(**train_eval_result))\n",
    "            self.eval_dict['train_accuracy'] = train_eval_result['accuracy']\n",
    "\n",
    "        # Prediction on the test set.\n",
    "        predict_test_input_fn = tf.estimator.inputs.pandas_input_fn(\n",
    "            self.test_df, self.test_df[\"label\"], shuffle=False)\n",
    "        test_eval_result = self.estimator.evaluate(input_fn=predict_test_input_fn)\n",
    "        print(\"Test set accuracy: {accuracy}\".format(**test_eval_result))\n",
    "        self.eval_dict['test_accuracy'] = test_eval_result['accuracy']\n",
    "\n",
    "    def compositionality_eval(self) -> None:\n",
    "        if self.estimator is None:\n",
    "            raise ValueError(\"Build self.estimator by calling self.build_model() before evaluation\")\n",
    "        comp_df = pd.read_csv(os.path.join(self.data_dir, 'compositionality_testing.csv'), encoding='latin1')\n",
    "        comp_df['text'] = comp_df['text1']\n",
    "        predict_test_input_fn1 = tf.estimator.inputs.pandas_input_fn(comp_df, comp_df[\"label1\"], shuffle=False)\n",
    "\n",
    "        comp_df['text'] = comp_df['text0']\n",
    "        predict_test_input_fn0 = tf.estimator.inputs.pandas_input_fn(comp_df, comp_df[\"label0\"], shuffle=False)\n",
    "\n",
    "        comp_df['preds0'] = [int(x[\"class_ids\"][0]) for x in self.estimator.predict(input_fn=predict_test_input_fn0)]\n",
    "        comp_df['preds1'] = [int(x[\"class_ids\"][0]) for x in self.estimator.predict(input_fn=predict_test_input_fn1)]\n",
    "        comp_df['correct'] = comp_df.apply(lambda x: int(x['preds0'] == 0 and x['preds1'] == 1), axis=1)\n",
    "        self.eval_dict['comp_accuracy_all'] = comp_df['correct'].mean()\n",
    "\n",
    "        comp_df['words_added'] = comp_df.apply(\n",
    "            lambda x: (set(word_tokenize(x['text1'])) - set(word_tokenize(x['text0']))), axis=1)\n",
    "        comp_df['num_words_added'] = comp_df.apply(lambda x: len(x['words_added']), axis=1)\n",
    "        comp_df = comp_df[comp_df['num_words_added'] > 0].reset_index(drop=True)\n",
    "        self.eval_dict['comp_accuracy_filter'] = comp_df['correct'].mean()\n",
    "        print(\"Switching accuracy Filtered= {}\".format(comp_df['correct'].mean()))\n",
    "        save_file = os.path.join(self.data_dir, 'compositionality_pred_{}.csv'.format(self.model_id))\n",
    "        comp_df.to_csv(save_file, index=False)\n",
    "\n",
    "    def run_all(self) -> None:\n",
    "        self.build_model()\n",
    "        self.train_model()\n",
    "        self.eval_model()\n",
    "        self.compositionality_eval()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pipeline = TFHubCompositionalitySwitchingPipeline('use_dan', True, 'linear')\n",
    "# pipeline.run_all()\n",
    "# pipeline.eval_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "param_vals = {'model_name': ['use_dan', 'use_large'], 'finetune_module': [True, False], 'last_layer': ['dnn']}\n",
    "param_grid = list(ParameterGrid(param_vals))\n",
    "pprint(param_grid)\n",
    "model_log_dict = OrderedDict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for params in param_grid:\n",
    "    pipeline = TFHubCompositionalitySwitchingPipeline(**params)\n",
    "    pipeline.run_all()\n",
    "    model_log_dict[pipeline.model_id] = pipeline.eval_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('model_log_dict_dnn.json', 'w') as f:\n",
    "    json.dump(str(model_log_dict), f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_log_df = pd.DataFrame.from_dict(model_log_dict, orient='index')\n",
    "model_log_df.to_csv('model_log_df_use_dnn.csv', index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_log_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "N6ZDpd9XzFeN"
   ],
   "default_view": {},
   "name": "Text classification with TF-Hub",
   "provenance": [],
   "version": "0.3.2",
   "views": {}
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
